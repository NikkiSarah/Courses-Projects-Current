1. EDA
Does it include a word count, some histograms, a few other visualizations, etc.? 

EDA goes above and beyond expectations: for example, in addition to exploring the dataset and getting a sense of word
count, class distribution, etc.,  EDA also  includes several histograms and other types of visualizations.


2. Data Cleaning
Does it include basic data cleaning like stop word removal?

Yes, it includes basic data cleaning. E.g., stop word removal. Explains the data cleaning procedure and reasoning for
methods/techniques chosen.


3. Plan based on EDA
Does it apply and explain a word feature extraction (e.g., word embedding) method and include a plan of analysis based
on the EDA?

Note, when you evaluate, don't base the score just on the complexity of the method or technique. Base your score on how
the learner demonstrates understanding by explaining the concepts and why they chose particular methods/techniques. 

Excellent application and explanation of a word feature extraction method with a thorough analysis plan based on the
EDA performed. The author provides strong reasoning for choosing a particular word feature extraction method/technique.


4. Matrix factorisation
Correctly uses a matrix factorization method with an explanation of choice. 
Recall these questions from the directions:
- Think about this and answer: when you train the unsupervised model for matrix factorization, should you include texts
(word features) from the test dataset or not as the input matrix? Why or why not?

Having word features from the test dataset texts included in the matrix X helps. Note: Some words might exist in one
data set but not in the other. Factorizing all together can build more vocabulary cases. Having both train and test
texts in the factorizing matrix does not lead to data leak as in supervised learning because the labels are not
involved.

- Build a model using the matrix factorization method(s) and predict the train and test data labels. Choose any
hyperparameter (e.g., number of word features) to begin with.

When choosing the number of features (word vectors) to include as a word feature matrix, it should not exceed the
number of vocabularies. 

Note, when you evaluate, don't just base your score on the complexity of the model/technique or performance of the
model alone. Base your score on how the learner demonstrates understanding by explaining the concepts and choice of
particular methods/techniques.

Correctly uses a matrix factorization method (eg. includes word features from the test dataset in the input marix,
number of features (word vectors) do not exceed the number of vocabularies, etc.) and explains chosen method. 


5. Hyperparameter tuning
To receive full points for this section, the author needs to address the following:
- Implements hyperparameter tuning procedure
- Correctly uses accuracy metric
- Uses additional metrics such as confusion matrix to inspect results
- Result tables or graph.visualization from hyperparameter tuning
- Shows some modification to improve performance (give full points if an idea was implemented or attempted, even if it
did not improve performance. Award partial points for mentioning ideas/suggestions without implementing.)

Used accuracy metric correctly (+3 pts), used additional metrics such as confusion matrix to inspect results (+2 pts),
result tables or graph/visualization from hyperparameter tuning (+5 pts), showed some modification to improve
performance (+5 pts); even if it did not improve, if an idea was implemented or tried give full points. If only
ideas/suggestions were mentioned, give partial points 2 pts.

Includes all of the following: hyperparameter tuning procedure and uses accuracy for evaluation metric and inspects
results utilizing additonal metrics like confusion marix and includes result tables or graph visualizations from
hyperparameter tuning and implements/atempts modification to improve performance (does not need to actually improve
performance).


6. Comparison with supervised learning
Does the comparison include the following:
- Uses a supervised learning model correctly. Preferrably uses multiple models.
- Displays tables or visualizations comparing train and test accuracies from each model, compared to matrix
  factorization.
- Implements experiments using random subsets of data.
- Shows tables/visualizations for experiments.
- Discusses comparison among unsupervised/supervised models on the data subsets (eg. data efficiency, performances,
  overfitting, etc.)  

Breakdown: Used a supervised learning model correctly (5 pts), Used multiple models (+5 pts), Displays tables or
visualizations comparing train and test accuracies from each model, comparing to matrix factorization (+5 pts).
Implemented experiments using random subsets of data (+5 pts), and shows tables/visualizations (+5 pts), discuss
comparison among unsupervised/supervised models on the data subsets (e.g. data efficiency, performances, overfitting
etc) (+5 pts)

Includes all of the following: uses a supervised learning model correctly and uses multiple models and displays tables
of visualizations comparing train and test accuracies from each model compared to matrix factorization and implements
experiments using random subsets of data and shows tables/visualizations for experiments and discusses comparisons
among unsupervised.supervised models on the data subsets (eg. data efficiency, performances, overfitting, etc.)


7. Overall quality
Is the writeup organized and clear?  

Yes, the write-up is organized, following a logical sequence that is easy to follow, and the writing is clear with
understandable explanations.  