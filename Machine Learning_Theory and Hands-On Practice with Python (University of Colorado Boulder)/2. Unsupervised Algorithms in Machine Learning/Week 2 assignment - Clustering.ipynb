{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "556d9673a40cef731438819650b4afeb",
     "grade": false,
     "grade_id": "cell-3fab386f48bbd974",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Grading\n",
    "This week's lab doesn't have any auto-graded components. Each question in this notebook has an accompanying Peer Review question. Although the lab shows as being ungraded, you need to complete the notebook to answer the Peer Review questions. <br>\n",
    "**DO NOT CHANGE VARIABLE OR METHOD SIGNATURES** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "19ae55b356f0ad3dfda48f3cb99dddb9",
     "grade": false,
     "grade_id": "cell-9488ace019b4c835",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Validate Button\n",
    "This week's lab doesn't have any auto-graded components. Each question in this notebook has an accompanying Peer Review question. Although the lab shows as being ungraded, you need to complete the notebook to answer the Peer Review questions. \n",
    "\n",
    "You do not need to use the Validate button for this lab since there are no auto-graded components. If you hit the Validate button, it will time out given the number of visualizations in the notebook. Cells with longer execution times cause the validate button to time out and freeze. ***This notebook's Validate button time-out does not affect the final submission grading.*** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "local-marketing",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "412c0fbff4d9e5401141ed5f953ba132",
     "grade": false,
     "grade_id": "cell-539bfe3db5c0f774",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Clustering RNA sequences to identify cancer types\n",
    "\n",
    "In this assignment, we will use clustering algorithms on RNA sequence data to identify cancer types.\n",
    "Since the [whole data](https://www.synapse.org/#!Synapse:syn4301332) (from [Cancer Genome Atlas Pan-Cancer project](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3919969/)) is very big, we will use a [subset data from UCI Machine Learning repository](https://archive.ics.uci.edu/ml/datasets/gene+expression+cancer+RNA-Seq#). The subset data contains only 5 labels; BRCA, KIRC, COAD, LUAD and PRAD. The meanings of those labels are as below.\n",
    "\n",
    "|Abbreviation|Cancer|\n",
    "|:----:|:-------:|\n",
    "|LUSC|Lung squamous cell carcinoma |\n",
    "|READ |Rectum adenocarcinoma |\n",
    "|GBM |Glioblastoma multiforme|\n",
    "|BLCA |Bladder Urothelial Carcinoma|\n",
    "|UCEC |Uterine Corpus Endometrioid Carcinoma|\n",
    "|COAD |Colon adenocarcinoma|\n",
    "|OV |Ovarian serous cystadenocarcinoma|\n",
    "|LAML |Acute Myeloid Leukemia|\n",
    "|HNSC |Head and Neck squamous cell carcinoma|\n",
    "|LUAD |Lung adenocarcinoma|\n",
    "|BRCA |Breast invasive carcinoma|\n",
    "|KIRC |Kidney renal clear cell carcinoma|\n",
    "\n",
    "Although we can use the data for supervised learning model training, we will not use these labels for training, but use them for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "ordered-pasta",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "deb30e3992bd6264bc0999a631f4f249",
     "grade": false,
     "grade_id": "cell-aae50706a878da7b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.cluster import AgglomerativeClustering, KMeans\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "forbidden-patrol",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7d54524a953add3d7536b6f813e910b6",
     "grade": false,
     "grade_id": "cell-0349e5e5a7302cd2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Read data. Do not change the variable names (data, label)\n",
    "data = pd.read_csv('data/data.csv')\n",
    "label = pd.read_csv('data/labels.csv')\n",
    "data=data.drop('Unnamed: 0',axis=1)\n",
    "label=label.drop('Unnamed: 0',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "universal-consultancy",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "70fad3bc72f0de4ef37faa39dbc1aca1",
     "grade": false,
     "grade_id": "cell-a2791930798cf4eb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### A. [Peer Review] Perform basic data inspection or EDA on the pandas dataframe.\n",
    "- How many observations?\n",
    "- How many features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3b9a724c90825ae8d7bc9a7d59a37620",
     "grade": false,
     "grade_id": "cell-2958c08df1714546",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene_0</th>\n",
       "      <th>gene_1</th>\n",
       "      <th>gene_2</th>\n",
       "      <th>gene_3</th>\n",
       "      <th>gene_4</th>\n",
       "      <th>gene_5</th>\n",
       "      <th>gene_6</th>\n",
       "      <th>gene_7</th>\n",
       "      <th>gene_8</th>\n",
       "      <th>gene_9</th>\n",
       "      <th>...</th>\n",
       "      <th>gene_20521</th>\n",
       "      <th>gene_20522</th>\n",
       "      <th>gene_20523</th>\n",
       "      <th>gene_20524</th>\n",
       "      <th>gene_20525</th>\n",
       "      <th>gene_20526</th>\n",
       "      <th>gene_20527</th>\n",
       "      <th>gene_20528</th>\n",
       "      <th>gene_20529</th>\n",
       "      <th>gene_20530</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.865642</td>\n",
       "      <td>2.718197</td>\n",
       "      <td>7.350099</td>\n",
       "      <td>10.006003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.764792</td>\n",
       "      <td>0.496922</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.088133</td>\n",
       "      <td>9.118313</td>\n",
       "      <td>10.004852</td>\n",
       "      <td>4.484415</td>\n",
       "      <td>9.614701</td>\n",
       "      <td>12.031267</td>\n",
       "      <td>9.813063</td>\n",
       "      <td>10.092770</td>\n",
       "      <td>8.819269</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.942955</td>\n",
       "      <td>4.453807</td>\n",
       "      <td>6.346597</td>\n",
       "      <td>10.056868</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.320331</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.371876</td>\n",
       "      <td>9.623335</td>\n",
       "      <td>9.823921</td>\n",
       "      <td>6.555327</td>\n",
       "      <td>9.064002</td>\n",
       "      <td>11.633422</td>\n",
       "      <td>10.317266</td>\n",
       "      <td>8.745983</td>\n",
       "      <td>9.659081</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.249582</td>\n",
       "      <td>3.707492</td>\n",
       "      <td>8.185901</td>\n",
       "      <td>9.504082</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.536589</td>\n",
       "      <td>1.811101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.719386</td>\n",
       "      <td>8.610704</td>\n",
       "      <td>10.485517</td>\n",
       "      <td>3.589763</td>\n",
       "      <td>9.350636</td>\n",
       "      <td>12.180944</td>\n",
       "      <td>10.681194</td>\n",
       "      <td>9.466711</td>\n",
       "      <td>4.677458</td>\n",
       "      <td>0.586693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.590339</td>\n",
       "      <td>2.787976</td>\n",
       "      <td>7.318624</td>\n",
       "      <td>9.987136</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.213464</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.785237</td>\n",
       "      <td>8.605387</td>\n",
       "      <td>11.004677</td>\n",
       "      <td>4.745888</td>\n",
       "      <td>9.626383</td>\n",
       "      <td>11.198279</td>\n",
       "      <td>10.335513</td>\n",
       "      <td>10.400581</td>\n",
       "      <td>5.718751</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.325242</td>\n",
       "      <td>3.805932</td>\n",
       "      <td>6.530246</td>\n",
       "      <td>9.560367</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.957027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.403075</td>\n",
       "      <td>8.594354</td>\n",
       "      <td>10.243079</td>\n",
       "      <td>9.139459</td>\n",
       "      <td>10.102934</td>\n",
       "      <td>11.641081</td>\n",
       "      <td>10.607358</td>\n",
       "      <td>9.844794</td>\n",
       "      <td>4.550716</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 20531 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     gene_0    gene_1    gene_2    gene_3     gene_4  gene_5    gene_6  \\\n",
       "796     0.0  1.865642  2.718197  7.350099  10.006003     0.0  6.764792   \n",
       "797     0.0  3.942955  4.453807  6.346597  10.056868     0.0  7.320331   \n",
       "798     0.0  3.249582  3.707492  8.185901   9.504082     0.0  7.536589   \n",
       "799     0.0  2.590339  2.787976  7.318624   9.987136     0.0  9.213464   \n",
       "800     0.0  2.325242  3.805932  6.530246   9.560367     0.0  7.957027   \n",
       "\n",
       "       gene_7  gene_8  gene_9  ...  gene_20521  gene_20522  gene_20523  \\\n",
       "796  0.496922     0.0     0.0  ...    6.088133    9.118313   10.004852   \n",
       "797  0.000000     0.0     0.0  ...    6.371876    9.623335    9.823921   \n",
       "798  1.811101     0.0     0.0  ...    5.719386    8.610704   10.485517   \n",
       "799  0.000000     0.0     0.0  ...    5.785237    8.605387   11.004677   \n",
       "800  0.000000     0.0     0.0  ...    6.403075    8.594354   10.243079   \n",
       "\n",
       "     gene_20524  gene_20525  gene_20526  gene_20527  gene_20528  gene_20529  \\\n",
       "796    4.484415    9.614701   12.031267    9.813063   10.092770    8.819269   \n",
       "797    6.555327    9.064002   11.633422   10.317266    8.745983    9.659081   \n",
       "798    3.589763    9.350636   12.180944   10.681194    9.466711    4.677458   \n",
       "799    4.745888    9.626383   11.198279   10.335513   10.400581    5.718751   \n",
       "800    9.139459   10.102934   11.641081   10.607358    9.844794    4.550716   \n",
       "\n",
       "     gene_20530  \n",
       "796    0.000000  \n",
       "797    0.000000  \n",
       "798    0.586693  \n",
       "799    0.000000  \n",
       "800    0.000000  \n",
       "\n",
       "[5 rows x 20531 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perform basic data inspection such as getting the number of observations and number of features\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# any missing values?\n",
    "data.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene_0</th>\n",
       "      <th>gene_1</th>\n",
       "      <th>gene_2</th>\n",
       "      <th>gene_3</th>\n",
       "      <th>gene_4</th>\n",
       "      <th>gene_5</th>\n",
       "      <th>gene_6</th>\n",
       "      <th>gene_7</th>\n",
       "      <th>gene_8</th>\n",
       "      <th>gene_9</th>\n",
       "      <th>...</th>\n",
       "      <th>gene_20521</th>\n",
       "      <th>gene_20522</th>\n",
       "      <th>gene_20523</th>\n",
       "      <th>gene_20524</th>\n",
       "      <th>gene_20525</th>\n",
       "      <th>gene_20526</th>\n",
       "      <th>gene_20527</th>\n",
       "      <th>gene_20528</th>\n",
       "      <th>gene_20529</th>\n",
       "      <th>gene_20530</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>801.000000</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>801.0</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>801.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.026642</td>\n",
       "      <td>3.010909</td>\n",
       "      <td>3.095350</td>\n",
       "      <td>6.722305</td>\n",
       "      <td>9.813612</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.405509</td>\n",
       "      <td>0.499882</td>\n",
       "      <td>0.016744</td>\n",
       "      <td>0.013428</td>\n",
       "      <td>...</td>\n",
       "      <td>5.896573</td>\n",
       "      <td>8.765891</td>\n",
       "      <td>10.056252</td>\n",
       "      <td>4.847727</td>\n",
       "      <td>9.741987</td>\n",
       "      <td>11.742228</td>\n",
       "      <td>10.155271</td>\n",
       "      <td>9.590726</td>\n",
       "      <td>5.528177</td>\n",
       "      <td>0.095411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.136850</td>\n",
       "      <td>1.200828</td>\n",
       "      <td>1.065601</td>\n",
       "      <td>0.638819</td>\n",
       "      <td>0.506537</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.108237</td>\n",
       "      <td>0.508799</td>\n",
       "      <td>0.133635</td>\n",
       "      <td>0.204722</td>\n",
       "      <td>...</td>\n",
       "      <td>0.746399</td>\n",
       "      <td>0.603176</td>\n",
       "      <td>0.379278</td>\n",
       "      <td>2.382728</td>\n",
       "      <td>0.533898</td>\n",
       "      <td>0.670371</td>\n",
       "      <td>0.580569</td>\n",
       "      <td>0.563849</td>\n",
       "      <td>2.073859</td>\n",
       "      <td>0.364529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.009284</td>\n",
       "      <td>8.435999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.930747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.853517</td>\n",
       "      <td>6.678368</td>\n",
       "      <td>8.669456</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.974942</td>\n",
       "      <td>9.045255</td>\n",
       "      <td>7.530141</td>\n",
       "      <td>7.864533</td>\n",
       "      <td>0.593975</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.299039</td>\n",
       "      <td>2.390365</td>\n",
       "      <td>6.303346</td>\n",
       "      <td>9.464466</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.676042</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.454926</td>\n",
       "      <td>8.383834</td>\n",
       "      <td>9.826027</td>\n",
       "      <td>3.130750</td>\n",
       "      <td>9.400747</td>\n",
       "      <td>11.315857</td>\n",
       "      <td>9.836525</td>\n",
       "      <td>9.244219</td>\n",
       "      <td>4.092385</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.143687</td>\n",
       "      <td>3.127006</td>\n",
       "      <td>6.655893</td>\n",
       "      <td>9.791599</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.450114</td>\n",
       "      <td>0.443076</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.972582</td>\n",
       "      <td>8.784144</td>\n",
       "      <td>10.066385</td>\n",
       "      <td>5.444935</td>\n",
       "      <td>9.784524</td>\n",
       "      <td>11.749802</td>\n",
       "      <td>10.191207</td>\n",
       "      <td>9.566511</td>\n",
       "      <td>5.218618</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.883484</td>\n",
       "      <td>3.802534</td>\n",
       "      <td>7.038447</td>\n",
       "      <td>10.142324</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.121984</td>\n",
       "      <td>0.789354</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.411292</td>\n",
       "      <td>9.147136</td>\n",
       "      <td>10.299025</td>\n",
       "      <td>6.637412</td>\n",
       "      <td>10.082269</td>\n",
       "      <td>12.177852</td>\n",
       "      <td>10.578561</td>\n",
       "      <td>9.917888</td>\n",
       "      <td>6.876382</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.482332</td>\n",
       "      <td>6.237034</td>\n",
       "      <td>6.063484</td>\n",
       "      <td>10.129528</td>\n",
       "      <td>11.355621</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.718190</td>\n",
       "      <td>2.779008</td>\n",
       "      <td>1.785592</td>\n",
       "      <td>4.067604</td>\n",
       "      <td>...</td>\n",
       "      <td>7.771054</td>\n",
       "      <td>11.105431</td>\n",
       "      <td>11.318243</td>\n",
       "      <td>9.207495</td>\n",
       "      <td>11.811632</td>\n",
       "      <td>13.715361</td>\n",
       "      <td>11.675653</td>\n",
       "      <td>12.813320</td>\n",
       "      <td>11.205836</td>\n",
       "      <td>5.254133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 20531 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           gene_0      gene_1      gene_2      gene_3      gene_4  gene_5  \\\n",
       "count  801.000000  801.000000  801.000000  801.000000  801.000000   801.0   \n",
       "mean     0.026642    3.010909    3.095350    6.722305    9.813612     0.0   \n",
       "std      0.136850    1.200828    1.065601    0.638819    0.506537     0.0   \n",
       "min      0.000000    0.000000    0.000000    5.009284    8.435999     0.0   \n",
       "25%      0.000000    2.299039    2.390365    6.303346    9.464466     0.0   \n",
       "50%      0.000000    3.143687    3.127006    6.655893    9.791599     0.0   \n",
       "75%      0.000000    3.883484    3.802534    7.038447   10.142324     0.0   \n",
       "max      1.482332    6.237034    6.063484   10.129528   11.355621     0.0   \n",
       "\n",
       "           gene_6      gene_7      gene_8      gene_9  ...  gene_20521  \\\n",
       "count  801.000000  801.000000  801.000000  801.000000  ...  801.000000   \n",
       "mean     7.405509    0.499882    0.016744    0.013428  ...    5.896573   \n",
       "std      1.108237    0.508799    0.133635    0.204722  ...    0.746399   \n",
       "min      3.930747    0.000000    0.000000    0.000000  ...    2.853517   \n",
       "25%      6.676042    0.000000    0.000000    0.000000  ...    5.454926   \n",
       "50%      7.450114    0.443076    0.000000    0.000000  ...    5.972582   \n",
       "75%      8.121984    0.789354    0.000000    0.000000  ...    6.411292   \n",
       "max     10.718190    2.779008    1.785592    4.067604  ...    7.771054   \n",
       "\n",
       "       gene_20522  gene_20523  gene_20524  gene_20525  gene_20526  gene_20527  \\\n",
       "count  801.000000  801.000000  801.000000  801.000000  801.000000  801.000000   \n",
       "mean     8.765891   10.056252    4.847727    9.741987   11.742228   10.155271   \n",
       "std      0.603176    0.379278    2.382728    0.533898    0.670371    0.580569   \n",
       "min      6.678368    8.669456    0.000000    7.974942    9.045255    7.530141   \n",
       "25%      8.383834    9.826027    3.130750    9.400747   11.315857    9.836525   \n",
       "50%      8.784144   10.066385    5.444935    9.784524   11.749802   10.191207   \n",
       "75%      9.147136   10.299025    6.637412   10.082269   12.177852   10.578561   \n",
       "max     11.105431   11.318243    9.207495   11.811632   13.715361   11.675653   \n",
       "\n",
       "       gene_20528  gene_20529  gene_20530  \n",
       "count  801.000000  801.000000  801.000000  \n",
       "mean     9.590726    5.528177    0.095411  \n",
       "std      0.563849    2.073859    0.364529  \n",
       "min      7.864533    0.593975    0.000000  \n",
       "25%      9.244219    4.092385    0.000000  \n",
       "50%      9.566511    5.218618    0.000000  \n",
       "75%      9.917888    6.876382    0.000000  \n",
       "max     12.813320   11.205836    5.254133  \n",
       "\n",
       "[8 rows x 20531 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 801 entries, 0 to 800\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Class   801 non-null    object\n",
      "dtypes: object(1)\n",
      "memory usage: 6.4+ KB\n"
     ]
    }
   ],
   "source": [
    "label.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BRCA    300\n",
       "KIRC    146\n",
       "LUAD    141\n",
       "PRAD    136\n",
       "COAD     78\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what's the actual distribution of the class labels?\n",
    "label.Class.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "65492cc771478d0c9c26f1a73857843a",
     "grade": false,
     "grade_id": "cell-bde1524da0e9a63f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "- Draw histograms of mean, max and min values in each feature. You may see numbers around 0-20. What do those numbers mean? (We do not expect students to know or figure out the meanings, but if you do know by chance, feel free to discuss them with the class on the discussion board.) <br>\n",
    "Answer the Peer Review question about this section. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b4abf73a9c24337560f0e0557bb0f7df",
     "grade": false,
     "grade_id": "cell-dcce43bb9bf942c0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# draw histograms of mean, max and min values in each feature\n",
    "\n",
    "# I like seaborn better than plain matplotlib\n",
    "import seaborn as sns\n",
    "\n",
    "# get the mean, max and min values of each feature\n",
    "data_agg = data.agg(['mean', 'max', 'min'])\n",
    "data_agg.reset_index(inplace=True, drop=False)\n",
    "# convert into a long format\n",
    "data_agg = pd.wide_to_long(data_agg, stubnames='gene_', i='index', j='feature').reset_index()\n",
    "data_agg.columns = ['stat', 'gene', 'value']\n",
    "\n",
    "stats = data_agg.stat.unique()\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15,5))\n",
    "\n",
    "for i, stat in enumerate(stats):\n",
    "    plot_data = data_agg.loc[data_agg.stat == stat, :]\n",
    "    f = sns.distplot(plot_data['value'], kde=False, ax=axs[i])\n",
    "    axs[i].set_title(stat)\n",
    "    sns.despine();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f10e915af8708dc8de4c6a2a8ca51108",
     "grade": false,
     "grade_id": "cell-6736f47726a243e7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "- If we were to train a \"supervised\" learning model, how would you deal with such large feature dimension? \n",
    "- Even after feature dimension reduction, still the number of useful features may be enormous. How it would impact performance or runtime of certain supervised learning algorithms? Which algorithms would suffer from high dimension features than others and why? \n",
    "- How it would impact performance or runtime of an unsupervised learning algorithm?\n",
    "- Draw histograms of mean, max and min values in each feature. You may see numbers around 0-20. What those numbers mean? (We do not expect students to know or figure out the meanings, but if you do know by chance, feel free to discuss them with the class on the discussion board.) <br> <br>\n",
    "Anwer these questions in this week's Peer Review assignment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. If I was training a supervised model and didn't want to see what happened if I used the dataset as is, I could try using principal components analysis or something equivalent to reduce the number of dimensions and use those uncorrelated features in the model. I could also use domain knowledge or call on subject-matter experts to determine if there were a core subset of genes that could be used instead of the entire set. If all else failed, I could use try a tree-based model with heavy feature sub-sampling.\n",
    "\n",
    "2. The higher the dimensionality of a dataset, irrespective of whether it's a large number of features, large number of cases or both, the longer any machine learning model takes to train and tune. However, some are more affected than others. Algorithms more sensitive to high feature dimensionality include:\n",
    "    - k-nearest neighbours because its a lazy algorithm that calculates distances between data points so more features means an exponential increase in the number of distance calculations\n",
    "    - decision tree ensembles like random forests and boosted tres because multiple trees are trained, which can be particularly computationally expensive when those trees have many branches and nodes\n",
    "    - support vector machines because the optimisation problem they solve is more complex as the number of features increases\n",
    "    \n",
    "3. Similarly, higher dimension datasets also affect the performance and runtime of unsupervised training algorithms.\n",
    "\n",
    "    - these algorithms often rely on performing calculations, transformations or distances between datapoints, so more datapoints means increased runtimes and memory requirements\n",
    "    - sparsity also increases, which can lead to poor algorithm performance as they struggle to find meaningful patterns or clusters in the data\n",
    "    \n",
    "4. See above for the plots of the distribution of mean, max and min values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "36d2fc3f5b54ad32960f5d4ae52f2100",
     "grade": false,
     "grade_id": "cell-f89786ce6c22a413",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### B. [Peer Review] Build a hierarchical clustering model\n",
    "Let's build a model using hierarchical clustering. Hierarchical clustering module is available from `sklearn.cluster.AgglomerativeClustering`. You can choose linkage type and metric. Please check its documentation for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "944b291a4ed47f6acd91034c448514b9",
     "grade": false,
     "grade_id": "cell-20bd5000b96709cd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**a) Number of clusters vs distance threshold**\n",
    "Oftentimes hierarchical clustering does not need to know the number of clusters in advance. Instead, one needs to choose threshold distance/similarity to cut the dendrogram later. The AgglomerativeClustering module lets you specify either the number of clusters (n_clusters) or the threshold (distance_threshold). Based on our data, which should we choose to set to which value and why? <br> <br>\n",
    "Answer this question in the Peer Review assignment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should choose to set the number of clusters because we know how many we should have (5). If we didn't have the true labels and there were no pre-conceived hypotheses about the number of clusters that should be present then the distance threshold maybe a better choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "479da534d14157edc6cab3a8c6dce4b6",
     "grade": false,
     "grade_id": "cell-1dcb3a4ab605373a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### b) Guess which metric?\n",
    "Can you guess which metric to use (distance-based vs. similarity-based) and why? \n",
    "This question is not graded, but we encourage you to share your thoughts with the class. See the ungraded discussion prompt for this week's material. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think a distance-based metric as all the feature variables are numeric and the values represent the expression levels of genes, which inherently have a natural notion of distance or dissimilarity. If the underlying data was gene expression changes, then a similarity metric would be more appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e2681cdcd943f508b334d717be6461f4",
     "grade": false,
     "grade_id": "cell-3bdcbf312ff9cbef",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### c) Build a model\n",
    "Build a model using n_clusters=5 option. Choose any metric and linkage type at first. Display the clustering result labels (you can just print out the result). Do not change the variable (model) name. Answer the question about this section in the Peer Review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7a026cf9b5831deeb187d3b6279c2cbd",
     "grade": false,
     "grade_id": "cell-a182891914c1787d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# build a model using n_clusters=5 option\n",
    "model=None\n",
    "# use the default options (linkage='ward', and metric='euclidean')\n",
    "model = AgglomerativeClustering(n_clusters=5)\n",
    "model.fit(data)\n",
    "labels_pred = model.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fa88212d918a8521a87412958a95f3ef",
     "grade": false,
     "grade_id": "cell-14da739b5647db81",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### d) Label permuation\n",
    "In clustering, the labels get assigned randomly, so the label numbering won't match the ground truth necessarily. Write a function below to find best matching label ordering based on the accuracy. Do not change the variable names. Answer the question about this section in the Peer Review. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f47665d2983a53c6a92c098e5070fc63",
     "grade": false,
     "grade_id": "cell-82b20e00978bc5e6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def label_permute_compare(ytdf, yp, n=5):\n",
    "    \"\"\"\n",
    "    ytdf: labels dataframe object\n",
    "    yp: clustering label prediction output\n",
    "    Returns permuted label order and accuracy. \n",
    "    Example output: (3, 4, 1, 2, 0), 0.74 \n",
    "    \"\"\"\n",
    "    # generate all the possible permutations of the predicted labels\n",
    "    all_permutations = list(itertools.permutations(set(yp)))\n",
    "    # extract the true labels from the dataframe\n",
    "    true_labels = ytdf.Class\n",
    "\n",
    "    best_acc = 0\n",
    "    best_mapping = None\n",
    "    best_permutation = None\n",
    "\n",
    "    # in each permutation\n",
    "    for permutation in all_permutations:\n",
    "        # pair each true label with a number \n",
    "        mapping = dict(zip(set(true_labels), permutation))\n",
    "        # recode the true labels according to the mapping\n",
    "        recoded_labels = [mapping[label] for label in true_labels]\n",
    "        # calculate the accuracy\n",
    "        acc = accuracy_score(recoded_labels, yp)\n",
    "\n",
    "        # find the permutation/mapping with the highest accuracy score\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_mapping = mapping\n",
    "            best_permutation = permutation\n",
    "\n",
    "    return best_permutation, best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cf8892a7991eab729501b9f12fa11ae1",
     "grade": false,
     "grade_id": "cell-e59b3dddfdc36871",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 0, 2, 1, 4) 0.9950062421972534\n"
     ]
    }
   ],
   "source": [
    "labelorder, acc = label_permute_compare(label, model.labels_)\n",
    "print(labelorder, acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "246f7bd7bd4cacc06d3d8e7b0811e06b",
     "grade": false,
     "grade_id": "cell-2dee0f590af15ca1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### e) Check confusion matrix\n",
    "Use sklearn's confusion matrix and display the results. Answer the Peer Review question about this section.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7db659d69e66d44725a24b1f90796541",
     "grade": false,
     "grade_id": "cell-b7fe98331f7b544f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[299,   0,   0,   1,   0],\n",
       "       [  0, 146,   0,   0,   0],\n",
       "       [  0,   0, 136,   0,   0],\n",
       "       [  2,   0,   0, 139,   0],\n",
       "       [  0,   0,   0,   1,  77]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display confusion matrix here\n",
    "mapping = dict(zip(set(label.Class), labelorder))\n",
    "recoded_labels = [mapping[label] for label in label.Class]\n",
    "\n",
    "conf_mat = confusion_matrix(recoded_labels, model.labels_)\n",
    "conf_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "49b995d1748051a814f09ae8878096cd",
     "grade": false,
     "grade_id": "cell-b51181ebab84b037",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### f) Change linkage method and distance metric. Which ones lead the best performance? Print out the accuracy and confusion matrix for the best model.\n",
    "<br> Answer the Peer Review questions about this section. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a13e0521cb941ebbe96ef06b0f48bf8c",
     "grade": false,
     "grade_id": "cell-03953f78e5852c9a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best overall\n",
      "AgglomerativeClustering(affinity='euclidean', compute_full_tree='auto',\n",
      "                        connectivity=None, distance_threshold=None,\n",
      "                        linkage='complete', memory=None, n_clusters=5)\n",
      "Model accuracy:  0.9313358302122348\n",
      "Model confusion matrix:\n",
      "[[146   0   0   0   0]\n",
      " [  0 271   7  22   0]\n",
      " [  0   0  55  23   0]\n",
      " [  0   2   0 139   0]\n",
      " [  0   1   0   0 135]]\n"
     ]
    }
   ],
   "source": [
    "# programmatically evaluate which linkage method and distance metric lead to the best performance\n",
    "# distances (affinity) available are: 'euclidean', 'l1', 'l2', 'manhattan', 'cosine', 'cityblock'\n",
    "# linkages available are: 'ward', 'complete', 'average', 'single'\n",
    "\n",
    "# generate all possible permutations of affinity and linkage (excluding ward)\n",
    "linkages = ['complete', 'average', 'single']\n",
    "distances = ['euclidean', 'l1', 'l2', 'manhattan', 'cosine', 'cityblock']\n",
    "permutations = itertools.product(distances, linkages)\n",
    "\n",
    "best_acc = 0\n",
    "best_model = None\n",
    "best_conf_mat = None\n",
    "\n",
    "models = []\n",
    "distances = []\n",
    "linkages = []\n",
    "scores = []\n",
    "\n",
    "for permutation in permutations:\n",
    "    # fit the model to each combination of distance and linkage methods\n",
    "    model = AgglomerativeClustering(n_clusters=5, affinity=permutation[0], linkage=permutation[1])\n",
    "    model.fit(data)\n",
    "    # generate the model predictions\n",
    "    labels_pred = model.labels_\n",
    "    \n",
    "    # find the true label permutation with the highest accuracy\n",
    "    labelorder, acc = label_permute_compare(label, labels_pred)\n",
    "\n",
    "    # generate the confusion matrix\n",
    "    mapping = dict(zip(set(label.Class), labelorder))\n",
    "    recoded_labels = [mapping[label] for label in label.Class]\n",
    "    conf_mat = confusion_matrix(recoded_labels, labels_pred)\n",
    "    \n",
    "    # find the model with the best accuracy\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_model = model\n",
    "        best_conf_mat = conf_mat\n",
    "    \n",
    "    models.append(model)\n",
    "    distances.append(model.affinity)\n",
    "    linkages.append(model.linkage)\n",
    "    scores.append(acc)\n",
    "        \n",
    "print('Best overall')\n",
    "print(best_model)\n",
    "print('Model accuracy: ', best_acc)\n",
    "print('Model confusion matrix:')\n",
    "print(best_conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>distance</th>\n",
       "      <th>linkage</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AgglomerativeClustering(affinity='euclidean', ...</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>complete</td>\n",
       "      <td>0.931336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AgglomerativeClustering(affinity='l2', compute...</td>\n",
       "      <td>l2</td>\n",
       "      <td>complete</td>\n",
       "      <td>0.931336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AgglomerativeClustering(affinity='cosine', com...</td>\n",
       "      <td>cosine</td>\n",
       "      <td>complete</td>\n",
       "      <td>0.740325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>AgglomerativeClustering(affinity='cityblock', ...</td>\n",
       "      <td>cityblock</td>\n",
       "      <td>complete</td>\n",
       "      <td>0.722846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AgglomerativeClustering(affinity='manhattan', ...</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>complete</td>\n",
       "      <td>0.722846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AgglomerativeClustering(affinity='l1', compute...</td>\n",
       "      <td>l1</td>\n",
       "      <td>complete</td>\n",
       "      <td>0.722846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AgglomerativeClustering(affinity='l2', compute...</td>\n",
       "      <td>l2</td>\n",
       "      <td>single</td>\n",
       "      <td>0.375780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>AgglomerativeClustering(affinity='cosine', com...</td>\n",
       "      <td>cosine</td>\n",
       "      <td>single</td>\n",
       "      <td>0.375780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AgglomerativeClustering(affinity='euclidean', ...</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>single</td>\n",
       "      <td>0.375780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AgglomerativeClustering(affinity='l1', compute...</td>\n",
       "      <td>l1</td>\n",
       "      <td>single</td>\n",
       "      <td>0.374532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AgglomerativeClustering(affinity='manhattan', ...</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>single</td>\n",
       "      <td>0.374532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>AgglomerativeClustering(affinity='cityblock', ...</td>\n",
       "      <td>cityblock</td>\n",
       "      <td>single</td>\n",
       "      <td>0.374532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AgglomerativeClustering(affinity='l1', compute...</td>\n",
       "      <td>l1</td>\n",
       "      <td>average</td>\n",
       "      <td>0.365793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AgglomerativeClustering(affinity='manhattan', ...</td>\n",
       "      <td>manhattan</td>\n",
       "      <td>average</td>\n",
       "      <td>0.365793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>AgglomerativeClustering(affinity='cityblock', ...</td>\n",
       "      <td>cityblock</td>\n",
       "      <td>average</td>\n",
       "      <td>0.365793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AgglomerativeClustering(affinity='l2', compute...</td>\n",
       "      <td>l2</td>\n",
       "      <td>average</td>\n",
       "      <td>0.364544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AgglomerativeClustering(affinity='euclidean', ...</td>\n",
       "      <td>euclidean</td>\n",
       "      <td>average</td>\n",
       "      <td>0.364544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>AgglomerativeClustering(affinity='cosine', com...</td>\n",
       "      <td>cosine</td>\n",
       "      <td>average</td>\n",
       "      <td>0.364544</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                model   distance   linkage  \\\n",
       "0   AgglomerativeClustering(affinity='euclidean', ...  euclidean  complete   \n",
       "6   AgglomerativeClustering(affinity='l2', compute...         l2  complete   \n",
       "12  AgglomerativeClustering(affinity='cosine', com...     cosine  complete   \n",
       "15  AgglomerativeClustering(affinity='cityblock', ...  cityblock  complete   \n",
       "9   AgglomerativeClustering(affinity='manhattan', ...  manhattan  complete   \n",
       "3   AgglomerativeClustering(affinity='l1', compute...         l1  complete   \n",
       "8   AgglomerativeClustering(affinity='l2', compute...         l2    single   \n",
       "14  AgglomerativeClustering(affinity='cosine', com...     cosine    single   \n",
       "2   AgglomerativeClustering(affinity='euclidean', ...  euclidean    single   \n",
       "5   AgglomerativeClustering(affinity='l1', compute...         l1    single   \n",
       "11  AgglomerativeClustering(affinity='manhattan', ...  manhattan    single   \n",
       "17  AgglomerativeClustering(affinity='cityblock', ...  cityblock    single   \n",
       "4   AgglomerativeClustering(affinity='l1', compute...         l1   average   \n",
       "10  AgglomerativeClustering(affinity='manhattan', ...  manhattan   average   \n",
       "16  AgglomerativeClustering(affinity='cityblock', ...  cityblock   average   \n",
       "7   AgglomerativeClustering(affinity='l2', compute...         l2   average   \n",
       "1   AgglomerativeClustering(affinity='euclidean', ...  euclidean   average   \n",
       "13  AgglomerativeClustering(affinity='cosine', com...     cosine   average   \n",
       "\n",
       "    accuracy  \n",
       "0   0.931336  \n",
       "6   0.931336  \n",
       "12  0.740325  \n",
       "15  0.722846  \n",
       "9   0.722846  \n",
       "3   0.722846  \n",
       "8   0.375780  \n",
       "14  0.375780  \n",
       "2   0.375780  \n",
       "5   0.374532  \n",
       "11  0.374532  \n",
       "17  0.374532  \n",
       "4   0.365793  \n",
       "10  0.365793  \n",
       "16  0.365793  \n",
       "7   0.364544  \n",
       "1   0.364544  \n",
       "13  0.364544  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(data={'model': models, 'distance': distances, 'linkage': linkages, 'accuracy': scores})\n",
    "results.sort_values('accuracy', ascending=False, inplace=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scikit-learn implementation has 'ward', 'complete', 'average', and 'single' as the possible linkage methods. Similarly, the distance metrics possible are 'euclidean', 'l1', 'l2', 'manhattan', 'cosine' and 'cityblock'. The 'ward' linkage method was dropped as it can only be used with euclidean distance, which was the first model tried. Apart from that, every single unique pair of linkage and distance methods were tried and the accuracy calculated to determine the best-performing model.\n",
    "\n",
    "The best-performing models (there were two with the exact same accuracy of 0.931336 to 5 decimal places) used a complete linkage method and either a euclidean distance or l1 distance method. All the other models using complete linkage were next, but accuracy dropped to 0.72 to 0.74. Both single linkage and average linkage models performed poorly.\n",
    "\n",
    "In a confusion matrix, the true labels are the rows and the predicted labels are the columns. Also, in this case note that the classes are in different orders; that is, class 5 in the first confusion matrix is class 3 in this confusion matrix. Either way, the main difference between this confusion matrix and the first one is that the complete linkage algorithm made many more incorrect predictions for two of the classes than the first one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9eeef63c833a862a824bd957b4569d81",
     "grade": false,
     "grade_id": "cell-6cd5993178e6f606",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### C. What about k-means clustering?\n",
    "Can we apply kmeans clustering on this data? Which clustering methods give a better performance? Is kmeans faster or slower?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 0.99501\n",
      "Run time:  5.9454 seconds\n"
     ]
    }
   ],
   "source": [
    "# check how long a hierarchical clustering algorithm takes\n",
    "start_time = time.time()\n",
    "model = AgglomerativeClustering(n_clusters=5)\n",
    "model.fit(data)\n",
    "labels_pred = model.labels_\n",
    "\n",
    "labelorder, acc = label_permute_compare(label, model.labels_)\n",
    "print(\"Model accuracy:\", round(acc, 5))\n",
    "run_time = time.time() - start_time\n",
    "print(\"Run time: \", round(run_time, 4), \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ff50d6cc5b9fbf0fface11dad35bfaba",
     "grade": false,
     "grade_id": "cell-2f77201b65ef6a7a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 0.99251\n",
      "Run time:  9.1011 seconds\n"
     ]
    }
   ],
   "source": [
    "# try to apply kmeans clustering on this data\n",
    "# time kmeans to compare to hierarchical clustering \n",
    "# your code here\n",
    "start_time = time.time()\n",
    "model = KMeans(n_clusters=5)\n",
    "model.fit(data)\n",
    "labels_pred = model.labels_\n",
    "\n",
    "labelorder, acc = label_permute_compare(label, model.labels_)\n",
    "print(\"Model accuracy:\", round(acc, 5))\n",
    "run_time = time.time() - start_time\n",
    "print(\"Run time: \", round(run_time, 4), \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, there is no reason why the K-Means clustering algorithm cannot be used on this data. The k-means algorithm with 5 clusters achieved an accuracy of 0.9925, which is very respectable and only slightly lower than the best performing hierarchical clustering model (0.9950). However, hierarchical clustering was faster at about 5.9 seconds compared to the 9.1 seconds the k-means model took."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "HW2-clustering.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
